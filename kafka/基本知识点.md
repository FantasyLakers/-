## 1、基本架构

Broker：Kafka 集群包含一个或多个服务器，服务器节点称为broker。

Producer ：生产者即数据的发布者，该角色将消息发布到Kafka的topic中。broker接收到生产者发送的消息后，broker将该消息**追加**到当前用于追加数据的segment文件中。生产者发送的消息，存储到一个partition中，生产者也可以指定数据存储的partition。

Topic：发布到kafka集群的每条消息都有一个类别，用Topic来表示。通常，不同应用产生不同类型的数据，可以设置不同的主题。一个主题一般会有多个消息的订阅者，当生产者发布消息到某个主题时，订阅了这个主题的消费者都可以接收到新写入的消息。

Partition：kafka为每个主题维护了分布式的分区partition日志文件，物理意义上可以把主题看做进行了分区的日志文件。主题的每个分区都是一个有序的、不可变的记录序列，新的消息会不断追加到日志中。分区中的每条消息都会按照时间顺序分配到一个单调递增的顺序编号，叫做偏移量，这个偏移量能够唯一的定位到当前分区中的每一条消息。

Consumer：消费者，可以从broker中读取数据。消费者可以消费多个topic中的数据。

Consumer Group：每一个Consumer隶属于一个特定的Consumer Group，一条消息可以被不同Group中的Consumer消费，但同一Group内的消息只能被一个Consumer消费

![images](https://github.com/FantasyLakers/my-lessons/blob/master/kafka/kafka%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E5%9B%BE.jpg?raw=true)



## 2、Replication和ISR

Replication：副本策略，是Kafka高可用的一种保障机制。一个分区可以有多个副本。没有副本的情况下，一旦broker宕机，其上所有的partition都不可消费。引入副本策略之后，同一个partition可以有多个副本，而这时需要在这些副本中选出一个leader，**生产者和消费者只和分区的leader直接交互**，其他副本作为follower从leader复制数据。在创建主题的时候，该主题的分区及副本会尽可能均匀地分布到Kafka集群的各个broker节点上，对应的leader副本的分配也比较均匀。Replication逻辑上是作用于Topic的，但实际上是体现在每一个Partition上。例如：有一个Topic，分区(partitions)数为3(分别为a, b, c)，副本因子(replication-factor)数也为3；其本质就是该Topic一共有3个a分区，3个b分区，3个c分区。

分区中所有副本统称AR（Assigned Replicas），所有与leader副本保持一定程度同步的副本组成ISR（in-sync-replicas）。生产者生产消息会先发送到leader副本，然后follower副本才能从leader副本中拉取消息进行同步，同步期间内follower副本相对于leader副本而言会有一定程度的滞后。前面所说的“一定程度”是指可以忍受的滞后范围，这个范围可以通过参数进行配置。与leader副本同步滞后过多的副本（不包括leader）副本，组成OSR(Out-Sync Relipcas)。

从isr中移除副本的条件：

- 根据副本与leader的交互时间差，如果大于配置文件中的参数，就认为该副本通讯异常，将此副本从isr中移除。由配置参数rerplica.lag.time.max.ms决定，单位毫秒。
- 根据副本与leader中的信息条数差值决定是否从isr中移除。由配置参数rerplica.lag.max.messages决定，单位条数。



## 3、ack机制

当生产者向broker发送数据时，有三种确认机制，可以通过request.required.acks参数来设置数据的可靠性级别：

- 0：生产者无需等待broker的确认而继续发送下一条消息。这种情况下效率高，可靠性低。

- 1：默认级别，生产者需要等待leader返回成功，才会继续发送下一条消息。如果此时leader宕机，follower还没同步消息，则会造成数据丢失。

- -1：需要所有follower响应确认给leader，生产者才会继续发送下一条消息。如果ISR中只有一个leader，此时退化成ack=1的级别，也会造成数据丢失。

  

## 4、LEO和HW

LEO：即日志末端位移 log end offset，记录了该副本底层日志log中下一条消息的位移值。也就是说，如果LEO=10，表示该副本中保存了10条消息，位移值范围是0-9。

HW：high watermark，定义消息可见性，表示消息被leader和isr内的follower都确认commit写入本地log文件的位置，在HW位置下的消息都可以被消费。

### follower何时更新LEO？

- follower副本中的LEO：当follower发送fetch请求后，leader将数据返回给follower，此时follower开始向底层log写日志，并更新LEO。
- leader中的follower副本备份LEO，一旦leader接收到follower的fetch请求，它首先会从自己的log中读取相应的数据，并且在给follower返回数据之前更新follower的LEO。

### follower何时更新HW？

​	follower更新HW在其更新LEO之后，一旦follower向log写完数据，它会尝试更新它自己的HW值。具体算法就是比较当前LEO值与fetch响应中leader中的HW值，取两者的小者为新的HW值。
leader副本何时更新LEO？
​	和follower更新LEO道理相同，leader写log时就会自动地更新它自己的LEO值。

### leader何时更新HW值？

leader的HW值就是分区的HW值，它直接影响了分区数据对于consumer的可见性。以下4中情况下会尝试去更新分区HW：

- follower副本成为leader副本时：当某个副本成为了分区的leader副本，Kafka会尝试去更新分区HW。这是显而易见的道理，毕竟分区leader发生了变更，这个副本的状态是一定要检查的！
- broker出现崩溃导致副本被踢出ISR时：若有broker崩溃则必须查看下是否会波及此分区，因此检查下分区HW值是否需要更新是有必要的。
- producer向leader副本写入消息时：因为写入消息会更新leader的LEO，故有必要再查看下HW值是否也需要修改
- leader处理follower FETCH请求时：当leader处理follower的FETCH请求时首先会从底层的log读取数据，之后会尝试更新分区HW值

当尝试更新分区HW值时，leader会选出所有满足条件的副本，比较他们的LEO，选出最小的LEO值最为分区HW。这里的满足条件主要是副本满足以下两个条件之一：

- 处于ISR中
- 副本LEO落后于leader的LEO的时长不大于replica.lag.time.max参数

乍看上去好像这两个条件说得是一回事，毕竟ISR的定义就是第二个条件描述的那样。但某些情况下Kafka的确可能出现副本已经“追上”了leader的进度，但却不在ISR中——比如某个从failure中恢复的副本。如果Kafka只判断第一个条件的话，确定分区HW值时就不会考虑这些未在ISR中的副本，但这些副本已经具备了“立刻进入ISR”的资格，因此就可能出现分区HW值越过ISR中副本LEO的情况——这肯定是不允许的，因为分区HW实际上就是ISR中所有副本LEO的最小值。

由于HW的更新是异步延迟的，特别是需要额外的fetch请求处理流程才能更新，故这之间的发生的任何broker崩溃都可能导致HW的过期，从而导致数据丢失或不一致。鉴于这些原因，kafka从0.11版本引入了leader epoch来取代HW。leader端多开辟出一段内存区域专门保存leader的epoch信息。所谓的epoch实际上是一对值（epoch，offset），epoch表示表示leader的版本号，从0开始，当leader变更时，epoch+1，而offset则对应于该epoch版本的leader写入第一条数据的位移。
因此假设有两对值：(0, 0)，(1, 120)，则表示第一个leader从位移0开始写入消息；共写了120条[0, 119]；而第二个leader版本号是1，从位移120处开始写入消息。
leader broker中会保存这样的一个缓存，并定期地写入到一个checkpoint文件中。当leader写底层log时它会尝试更新整个缓存——如果这个leader首次写消息，则会在缓存中增加一个条目；否则就不做更新。而每次副本重新成为leader时会查询这部分缓存，获取出对应leader版本的位移，这就不会发生数据不一致和丢失的情况。



## 5、生产者负载均衡

对于同一个Topic的不同Partition，Kafka会尽力将这些Partition分布到不同的Broker服务器上，这种均衡策略实际上是基于Zookeeper实现的。在一个Broker启动时，会首先完成Broker的注册过程，并注册一些诸如“有哪些可订阅的Topic”之类的元数据信息。生产者启动后也要到zookeeper下注册，创建一个临时节点来监听Broker服务器列表的变化。由于在Zookeeper下Broker创建的是临时节点，当Brokers发生变化时，生产者可以得到相关的通知，从改变自己的Broker list。其他的诸如Topic的变化以及Broker和Topic的关系变化，也是通过Zookeeper的这种Watcher监听实现的。

- 生产者指定了分区，则数据直接发送到指定分区
- 生产者未指定分区，但指定了key，通过key的哈希值找出对应分区
- 生产者未指定key，则生产者通过轮询的方式将数据发送到对应分区



## 6、消费者负载均衡

Kafka具有消费分组的概念，某个Topic的某个partition只能由一个Consumer group中的一个Consmer消费。但如果两个Consmer不在同一个Consumer group，那么他们是可以同时消费某Topic的同一个partition的。 消费者在启动时会到zookeeper下以自己的conusmer-id创建临时节点/consumer/[group-id]/ids/[conusmer-id]，并对/consumer/[group-id]/ids注册监听事件，当消费者发生变化时，同一group的其余消费者会得到通知。当然，消费者还要监听broker列表的变化。

消费者分区策略：

- Range strategy（范围分区） 默认策略， range策略针对于每个topic，**各个topic之间分配时没有任何关联**，分配步骤如下： 

  - topic下的所有有效分区平铺，例如P0, P1, P2, P3… … 
  - 消费者按照字典排序，例如C0, C1, C2 
  - 分区数除以消费者数，得到n 
  - 分区数对消费者数取余，得到m 
  - 消费者集合中，前m个消费者能够分配到n+1个分区，而剩余的消费者只能分配到n个分区。

  eg：对于某个topic来说： 如果有5个分区（P0, P1, P2, P3, P4），且订阅这个topic的消费者组有2个消费者（C0, C1）。那么P0, P1, P2将被C0消费，P3, P4将被C1消费。 如果有4个分区（P0, P1, P2, P3），且订阅这个topic的消费者组有2个消费者（C0, C1）。那么P0, P1将被C0消费，P3, P4将被C1消费。由上面的分析可知，range策略会把无法整除的剩余分区，分配给前面几个消费者，而且每个topic都会如此。这样的话，topic越多，前面几个消费者可能承受的压力就越大。

- RoundRobin strategy（轮询分区），**roundrobin策略针对于全局所有的topic和消费者**，分配步骤如下： 

  - 消费者按照字典排序，例如C0, C1, C2… …，并构造环形迭代器。 
  - topic名称按照字典排序，并得到每个topic的所有分区，从而得到所有分区集合。 
  - 遍历第2步所有分区集合，同时轮询消费者。 
  - 如果轮询到的消费者订阅的topic不包括当前遍历的分区所属topic，则跳过；否则分配给当前消费者，并继续第3步

  eg：对于某个topic来说： 如果有5个分区（P0, P1, P2, P3, P4），且订阅这个topic的消费者组有2个消费者（C0, C1）。那么P0, P2, P4将被C0消费，P1, P3将被C1消费。

  

### Rebalance

当一个消费者组中,有consumer加入或者离开时,会触发Rebalance,Rebalance的最终目的,是提升topic的并发消费能力。触发Rebalance的条件：

- 有新的消费者加入Consumer Group

- 有消费者下线，可能由于长时间未向GroupCoordinator(协调者)发送心跳，GroupCoordinator会认为其已下线

- 有消费者主动退出Consumer Group

- 订阅的topic分区出现变化

- 调用unsubscribe()取消对某Topic的订阅

  

## 7、控制器

在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器（Kafka Controller），它负责管理整个集群中所有分区和副本的状态。当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责分区的重新分配。
kafka在每个broker启动时，都会实例化一个kafkacontroller，并将broker的id注册到zookeeper，集群在启动过程中，通过选举机制选出其中一个broker作为leader，也就是控制器。包括集群启动在内，一共有三种情况触发控制器选举：

- 集群启动时，最先将自己的broker id写入zookeeper的就会成为leader。
- 控制器所在broker发生故障
- zookeeper心跳感知，控制器与自己的session过期

此外zk中还有controller_epoch节点，这个节点是持久（PERSISTENT）节点，存储了leader的变更次数，初始值为0，以后leader每变一次，该值+1。所有向控制器发起的请求，都会携带此值。如果控制器和自己内存中比较，请求值小，说明kafka集群已经发生了新的选举，此请求过期，此请求无效。如果请求值大于控制器内存的值，说明已经有新的控制器当选了，自己已经退位，请求无效。kafka通过controller_epoch保证集群控制器的唯一性及操作的一致性。

具备控制器的broker比其他broker多一份职责，具体如下：

- 监听partition的变化：分区重分配、ISR集合变更、副本选举

- 监听topic相关的变化：topic的增减与删除

- 监听broker的变化：处理broker的增减

- 从zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。

- 启动并管理分区状态机和副本状态机

- 更新集群的元数据信息

- 如果参数auto.leader.rebalance.enable设置为true，则还会开启一个名为“auto-leader-rebalance-task”的定时任务来负责维护分区的优先副本的均衡

  

## 8、协调器

消费者协调器：ConsumerCoordinator，主要作用有：

- 处理更新消费者缓存的metadata请求
- 向组协调器发起加入消费者组的请求
- 对本消费者加入消费者前后的相应处理
- 请求离开消费者组
- 向组协调器发送提交偏移量的请求
- 通过一个定时的心跳检测任务来让组协调器感知自己的运行状态
- 被组协调器选为leader的消费者的协调器，负责消费者分区分配。分配结果发送给组协调器。非leader的消费者，通过消费者协调器和组协调器同步分配结果。

组协调器：GroupCoordinator，主要作用有

- 通过心跳检测消费者与自己的连接状态
- 启动组协调器的时候创建一个定时任务，用于清理过期的消费者组元数据以及过期的消费偏移量信息
- 管理与之连接的消费者的消费偏移量的提交，将每个消费者的消费偏移量保存到kafka的内部主题中
- 当leader分配好消费者与分区的订阅关系后，会把结果发送给组协调器，组协调器再把结果返回给各个消费者
- 与消费者之间建立连接，并从与之连接的消费者之间选出一个leader

### 关于消费者偏移量的维护

​	消费者消费时，会在本地维护消费到的位置（offset），就是偏移量，这样下次消费才知道从哪里开始消费。如果整个环境没有变化，这样做就足够了。但一旦消费者平衡操作或者分区变化后，消费者不再对应原来的分区，而每个消费者的offset也没有同步到服务器，这样就无法接着前任的工作继续进行了。因此只有把消费偏移量定期发送到服务器，由GroupCoordinator集中式管理，分区重分配后，各个消费者从GroupCoordinator读取自己对应分区的offset，在新的分区上继续前任的工作。

### 偏移量的提交方式

- 自动提交偏移量，设置 enable.auto.commit为true，设定好周期，默认5s。消费者每次调用轮询消息的poll() 方法时，会检查是否超过了5s没有提交偏移量，如果是，提交上一次轮询返回的偏移量。
- 手动提交偏移量，设置 enable.auto.commit为false。程序中手动调用commitSync()或commitAsync()提交偏移量，此时提交的是poll方法返回的最新的偏移量。commitSync只要没有发生不可恢复错误，会进行重试，直到成功。而commitAsync不会进行重试，失败就是失败了。commitAsync不重试，是因为重试提交时，可能已经有其它更大偏移量已经提交成功了，如果此时重试提交成功，那么更小的偏移量会覆盖大的偏移量。那么如果此时发生再均衡，新的消费者将会重复消费消息。commitAsync也支持回调，由于上述原因，回调中最好不要因为失败而重试提交。而是应该记录错误，以便后续分析和补偿。



## 9、日志管理器

消息存储的单位为segment：logSegment代表逻辑上的一组文件，这组文件就是.log、.index、.timeindex这三个不同文件扩展名，但是同文件名的文件。这三个文件配合使用，用来保存和消费时快速查找消息。
日志定位也就是消息定位，输入一个消息的offset，kafka如何定位到这条消息呢？日志定位的过程如下:

- 根据offset定位logSegment。（kafka将基础偏移量也就是logsegment的名称作为key存在concurrentSkipListMap中）

- 根据logSegment的index文件查找到距离目标offset最近的被索引的offset的position x。

- 找到logSegment的.log文件中的x位置，向下逐条查找，找到目标offset的消息。

  

kafka提供两种日志清理策略：压缩和删除。通过参数配置，日志清理可以控制到主题级别，为不同的主题提供不同的清理策略。日志删除：无论消息是否被消费，kafka都会保留所有消息。有两种策略可以删除旧数据：

- 基于时间：log.retention.hours=168
- 基于大小：log.retention.bytes=1073741824



## 10、副本管理器

副本管理器负责分区及其副本的管理，副本管理器的职责如下：

- 副本过期检查

- 追加消息

- 拉取消息

- 副本同步过程

- 副本角色转换

- 关闭副本

  

## 11、JMS和AMQP

- JMS（java message service ）
  JMS提供了两种消息模型，点对点模型（peer-2-peer）以及发布订阅模型(publish-subscribe)。当采用点对点模型时，消息将发送到一个队列，且消息只能被一个消费者所消费。当采用发布订阅模型时，消息可以被多个消费者消费。
- AMQP（advanced message queuing protocol）
  AMQP可以跨语言跨平台，而JMS只能是java。AMQP提供了五种消息模型，direct、fanout、topic、headers、system。direct为点对点，fanout是广播，topic为发布订阅模型。



## 12、为什么使用消息中间件

消息中间件在特定场景下能起到异步、解耦、削峰的作用。

- 异步：A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。最终请求总延时是 3 + 300 + 450 + 200 = 953ms，接近 1s。如果使用 MQ，那么 A 系统连续发送 3 条消息到 MQ 队列中，假如耗时 5ms，A 系统从接受一个请求到返回响应给用户，总时长是 3 + 5 = 8ms。
- 解耦：A系统需要将消息推送给其他系统，万一其他系统下线了，需要修改代码，而使用中间件，则不需要。
- 削峰：高峰期数据库可能处理不了高并发的写入操作，先将这些操作写入消息中间件，后台系统慢慢处理，避免压死数据库。

### 消息中间件带来的问题

- 系统可用性降低：新加入消息中间件系统后怎么保证系统的高可用
- 系统复杂性提高：怎么保证消息不丢失？怎么处理消息重复消费的问题？怎么保证消息传递的顺序性
- 一致性问题：多个系统读取消息中间件的消息，其中一个系统消费失败了怎么处理？



## 13、如何保证消费的顺序性？

以kafka为例，根据数据的key指定将数据发送到特定分区，在consumer端单线程处理消息，如果单线程消费速度太慢，可以新建多个内存queue，相同key的数据发送到同一个queue中，保证消费的顺序和生产的顺序一致。


