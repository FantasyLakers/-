
# 1、IO模型
阻塞IO，非阻塞IO，多路复用IO，信号驱动IO、异步IO。
- 阻塞IO：blocking IO，当用户线程发出IO请求后，内核回去查看是否有数据就绪，如果没有数据就绪，用户线程就会处于阻塞状态，用户线程交出CPU，当数据准备好后，内核会将数据拷贝到用户线程，并返回结果给用户线程，此时用户线程解除block状态。
- 非阻塞IO：noblocking IO，当用户线程发起一个read操作后，并不需要等待，而是马上就得到了一个结果。如果结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦内核中的数据准备好了，并且又再次收到了用户线程的请求，那么它马上就将数据拷贝到了用户线程，然后返回。所以事实上，在非阻塞IO模型中，用户线程需要不断地询问内核数据是否就绪，也就说非阻塞IO不会交出CPU，而会一直占用CPU。
- 信号驱动IO：signal blocking IO，在信号驱动IO模型中，当用户线程发起一个IO请求操作，会给对应的socket注册一个信号函数，然后用户线程会继续执行，当内核数据就绪时会发送一个信号给用户线程，用户线程接收到信号之后，便在信号函数中调用IO读写操作来进行实际的IO请求操作。这个一般用于UDP中，对TCP套接口几乎是没用的，原因是该信号产生得过于频繁，并且该信号的出现并没有告诉我们发生了什么事情。
- 多路复用IO：IO multiplexing，java中的NIO模型。在多路复用IO模型中，会有一个线程不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真正调用实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。另外多路复用IO为何比非阻塞IO模型的效率高是因为在非阻塞IO中，不断地询问socket状态是通过用户线程去进行的，而在多路复用IO中，轮询每个socket状态是内核在进行的，这个效率要比用户线程要高的多。不过要注意的是，多路复用IO模型是通过轮询的方式来检测是否有事件到达，并且对到达的事件逐一进行响应。因此对于多路复用IO模型来说，一旦事件响应体很大，那么就会导致后续的事件迟迟得不到处理，并且会影响新的事件轮询。
- 异步IO：asynchronous IO，异步IO模型才是最理想的IO模型，在异步IO模型中，当用户线程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从内核的角度，当它受到一个asynchronous read之后，它会立刻返回，说明read请求已经成功发起了，因此不会对用户线程产生任何block。然后，内核会等待数据准备完成，然后将数据拷贝到用户线程，当这一切都完成之后，内核会给用户线程发送一个信号，告诉它read操作完成了。也就说用户线程完全不需要关心实际的整个IO操作是如何进行的，只需要先发起一个请求，当接收内核返回的成功信号时表示IO操作已经完成，可以直接去使用数据了。也就说在异步IO模型中，IO操作的两个阶段都不会阻塞用户线程，这两个阶段都是由内核自动完成，然后发送一个信号告知用户线程操作已完成。用户线程中不需要再次调用IO函数进行具体的读写。这点是和信号驱动模型有所不同的，在信号驱动模型中，当用户线程接收到信号表示数据已经就绪，然后需要用户线程调用IO函数进行实际的读写操作；而在异步IO模型中，收到信号表示IO操作已经完成，不需要再在用户线程中调用iO函数进行实际的读写操作。注意，异步IO是需要操作系统的底层支持，在Java 7中，提供了Asynchronous IO。简称AIO。

前面四种IO模型实际上都属于同步IO，只有最后一种是真正的异步IO，因为无论是多路复用IO还是信号驱动模型，IO操作的第2个阶段都会引起用户线程阻塞，也就是从内核进行数据拷贝的过程都会让用户线程阻塞。

# 2、https
[https加解密流程](https://blog.csdn.net/qq_1290259791/article/details/85939246)

# 3、tcp三次握手和四次挥手
[面试官，不要再问我三次握手和四次挥手](https://blog.csdn.net/hyg0811/article/details/102366854)

# 4、一个TCP连接上面能发多少个 HTTP 请求
[一个 TCP 连接上面能发多少个 HTTP 请求](https://zhuanlan.zhihu.com/p/61423830)

# 5、负载均衡
[故事版](https://blog.csdn.net/csdnsevenn/article/details/90528390)  
[常见的几种负载均衡原理](https://blog.csdn.net/bpb_cx/article/details/82771168)  
[三大主流负载均衡器LVS、Nginx、HAproxy详解](https://blog.csdn.net/lilygg/article/details/89538862)

# 6、http1.x和http2.0
 HTTP:超文本传输协议，它是在应用层上的协议，依赖传输层的TCP/IP协议。创建一个TCP连接是需要经过三次握手的,有一定的开销，如果每次通讯都要重新建立连接的话，对性能有影响。因此最好能维持一个长连接
- HTTP1.0：HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。
- HTTP1.1：这是一个使用了很长时间的协议，并且目前还在使用，它的前面有0.9、1.0。HTTP1.1默认是个持久连接，也就是不用频繁去创建连接，这对性能上提升是很大的，大家都知道，HTTP连接的创建是耗性能的。以前的版本都是发一个请求，服务器回应后就会断开连接，下一个请求时会重新创建连接。显然，这种情况是必需改进的，于是有了HTTP1.1。虽然它是个长连接，但在连接中发送的多个请求还是会顺序处理。这样的话一旦有一个请求处理很久的话，那后面的请求就会被阻塞。
- HTTP2.0： http2有哪些新特性？
  - HTTP2.0提供了 Multiplexing 多路传输特性，可以在一个 TCP 连接中同时完成多个 HTTP 请求，多路复用为每一个请求带一个编号，这样服务器方就能为请求的回应对上号了。如果一个请求时间过长，那么服务器就可以先暂停这个请求，先处理下一个请求，处理完再回来处理这个长请求，如何找回这个长请求呢，那就靠这个编号了。
  - 新的二进制格式（Binary Format），HTTP1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。
  - header压缩，HTTP1.x的header带有大量信息，而且每次都要重复发送，HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。
  - 服务端推送（server push），HTTP 2.0新增加服务器提示，可以先于客户端检测到将要请求的资源，提前通知客户端，服务器不发送所有资源的实体，只发送资源的URL，客户端接到提示后会进行验证缓存，如果真需要这些资源，则正式发起请求（服务器主动更新静态资源）。
