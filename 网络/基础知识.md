
# 1、http1.x和http2.0
 HTTP:超文本传输协议，它是在应用层上的协议，依赖传输层的TCP/IP协议。创建一个TCP连接是需要经过三次握手的,有一定的开销，如果每次通讯都要重新建立连接的话，对性能有影响，因此最好能维持一个长连接。
- HTTP1.0：HTTP 1.0需要使用keep-alive参数来告知服务器端要建立一个长连接，而HTTP1.1默认支持长连接。
- HTTP1.1：这是一个使用了很长时间的协议，并且目前还在使用，它的前面有0.9、1.0。HTTP1.1默认是个持久连接，也就是不用频繁去创建连接，这对性能上提升是很大的，大家都知道，HTTP连接的创建是耗性能的。以前的版本都是发一个请求，服务器回应后就会断开连接，下一个请求时会重新创建连接。显然，这种情况是必需改进的，于是有了HTTP1.1。虽然它是个长连接，但在连接中发送的多个请求还是会顺序处理。这样的话一旦有一个请求处理很久的话，那后面的请求就会被阻塞。
- HTTP2.0： http2有哪些新特性？
  - HTTP2.0提供了 Multiplexing 多路传输特性，可以在一个 TCP 连接中同时完成多个 HTTP 请求，多路复用为每一个请求带一个编号，这样服务器方就能为请求的回应对上号了。如果一个请求时间过长，那么服务器就可以先暂停这个请求，先处理下一个请求，处理完再回来处理这个长请求，如何找回这个长请求呢，那就靠这个编号了。
  - 新的二进制格式（Binary Format），HTTP1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。
  - header压缩，HTTP1.x的header带有大量信息，而且每次都要重复发送，HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。
  - 服务端推送（server push），HTTP 2.0新增加服务器提示，可以先于客户端检测到将要请求的资源，提前通知客户端，服务器不发送所有资源的实体，只发送资源的URL，客户端接到提示后会进行验证缓存，如果真需要这些资源，则正式发起请求（服务器主动更新静态资源）。

# 2、https建立连接过程
[https加解密流程](https://blog.csdn.net/qq_1290259791/article/details/85939246)

# 3、tcp三次握手和四次挥手
[面试官，不要再问我三次握手和四次挥手](https://blog.csdn.net/hyg0811/article/details/102366854)

# 4、一个TCP连接上面能发多少个 HTTP 请求
[一个 TCP 连接上面能发多少个 HTTP 请求](https://zhuanlan.zhihu.com/p/61423830)

# 5、负载均衡
[故事版](https://blog.csdn.net/csdnsevenn/article/details/90528390)  
[常见的几种负载均衡原理](https://blog.csdn.net/bpb_cx/article/details/82771168)  
[三大主流负载均衡器LVS、Nginx、HAproxy详解](https://blog.csdn.net/lilygg/article/details/89538862)

## 6、TCP协议简介

TCP协议：传输控制协议（transmission control protocol）是一种面向连接的、可靠的、基于字节流的**传输层**通信协议。

TCP通过下列方式来提供可靠性：

- 应用数据被分割成TCP认为最合适发送的数据块。这和UDP完全不同，应用程序产生的数据长度将保持不变。由TCP传递给ip的信息单位称为报文段或段（segment）
- 当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。TCP有延迟确认的功能
- TCP将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的校验和有差错，TCP将丢弃这个报文段且不会发送确认
- TCP报文段作为ip数据报来传输，而ip数据报的到达可能为失序，因此TCP报文段的到达也可能会失序。如果必要，TCP将对收到的数据进行重排序，将收到的数据一正确的顺序交给应用层
- TCP还能提供流量控制。TCP连接的每一方都有固定大小的缓冲区。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据。这将防止较快主机致使较慢主机的缓冲区溢出。



### TCP缓冲区

每一个TCP的套接字（socket）都有两个缓冲区，发送缓冲区和接收缓冲区。系统专门为socket开辟了一块内存，作为缓冲区的空间。write和send并不立即向网络中传输数据，而是先将数据写入缓冲区中，再由TCP协议将数据从缓冲区发送到目标机器。一旦将数据写入到缓冲区，函数就可以成功返回。

TCP协议独立于write和send函数，数据有可能刚被写入缓冲区就发送到网络，也可能在缓冲区中不断积压，多次写入的数据被一次性发送到网络。

read和recv函数也是如此，也从接收缓冲区中读取数据，而不是直接从网络中读取。



### MTU和MSS

MTU：maximum transmission unit，最大传输单元，由硬件规定，典型的以太网MTU为1500字节

MSS：maximum segment size，最大分段大小，为TCP数据包每次传输的最大数据分段大小。在TCP三次握手阶段，双方都会在各自SYN帧携带各自的MSS值

MTU = MSS + TCP header + IP header



### TCP的工作模式

单工：数据传输只支持数据在一个方向上传输，即只能从A到B，不能从B到A

半双工：允许数据在两个方向上传输，但是，在某一时刻，只允许数据在一个方向上传输

全双工：允许数据同时在两个方向上传输



### 粘包和拆包

TCP协议并不了解上层业务数据的具体界限，它会根据TCP缓冲区的实际情况进行包的拆分，所以在业务上认为，一个完整的包可能会被TCP拆分成多个包进行发送，TCP协议也有可能把多个小的包封装成一个大的数据包发送，这就是所谓的TCP粘包和拆包问题。

假设客户端分别发送了两个数据包D1和D2给服务端，由于服务端一次读取到的字节数是不确定的，故可能存在以下五种情况：

- 服务端分两次读取到了两个独立的数据包，分别是D1和D2，没有粘包和拆包
- 服务端一次接收到了两个数据包，D1和D2粘合在一起，被称为TCP粘包
- 服务端分两次读取到了两个数据包，第一次读取到了完整的D1包和D2包的部分内容，第二次读取到了D2包的剩余内容，这被称为TCP拆包
- 服务端分两次读取到了两个数据包，第一次读取到了D1包的部分内容D1_1，第二次读取到了D1包的剩余内容D1_2和D2包的整包
- 如果此时服务端TCP接收滑窗非常小，而数据包D1和D2比较大，则服务端分多次才能将D1和D2包接收完全，期间发生多次拆包



### 粘包和拆包发生的原因

- 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包
- 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包
- 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包
- 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包，即TCP报文长度-TCP头部长度 > MSS



### 粘包和拆包解决策略

- 消息定长，发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来
- 设置消息边界，服务端从网络流中按消息边界分离出消息内容。在包尾增加回车换行符进行分割，例如FTP协议
- 将消息分为消息头和消息体，消息头中包含表示消息总长度或消息体长度的字段
- 更复杂的应用层协议，例如HTTP协议


