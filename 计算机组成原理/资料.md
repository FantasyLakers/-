# 计算机组成原理

## 1、原码----原码的设计不便于加减运算
最高位表示符号位  
例如 0 = 0000 0000 ， -0 = 1000 0000  
例如 1 = 0000 0001  ，-1 = 1000 0001  
例如 5 = 0000 0101  ， -5 = 1000 0101  

## 2、反码----反码的设计也不便于加减运算
正数的反码是其本身，负数的反码是在其原码基础上，符号位不变，其他位按位取反  
例如 0 = 0000 0000 ， -0 = 1111 1111  
例如 1 = 0000 0001 ， -1 = 1111 1110  
例如 5 = 0000 0101  ， -5 = 1111 1010  

## 3、补码
正数的补码是其本身，负数的补码是在其原码基础上，符号位不变，其他位按位取反，最后加一，即在反码的基础上加一。补码没有正0与负0之分，都是0000 0000。  
计算机中正数用原码表示，负数用补码表示，且计算机只用加法器来计算加减法。  
例如 1 = 0000 0001 ， -1 = 1111 1111  
例如 5 = 0000 0101  ， -5 = 1111 1011  

## 4、内存

## 5、Linux中的用户空间和内核空间
- 用户空间（User Space）：应用程序的运行空间
- 内核空间（Kernel Space）：内核的运行空间，操作系统和驱动程序运行在内核空间。    

内核态和用户态有自己的内存映射，即自己的地址空间。为了安全，用户空间和内核空间是隔离的，即使用户的进程崩溃了，也不影响内核。正是有了不同运行状态的划分，才有了上下文的概念。用户空间的应用程序，如果想要请求系统服务，比如操作一个物理设备，或者映射一段设备空间的地址到用户空间，就必须通过系统调用来(操作系统提供给用户空间的接口函数)实现。  
通过系统调用，用户空间的应用程序就会进入内核空间，由内核代表该进程运行于内核空间，这就涉及到上下文的切换，用户空间和内核空间具有不同的地址映射，通用或专用的寄存器组，而用户空间的进程要传递很多变量、参数给内核，内核也要保存用户进程的一些寄存器、变量等，以便系统调用结束后回到用户空间继续执行，所谓的进程上下文，就是一个进程在执行的时候，CPU的所有寄存器中的值、进程的状态以及堆栈中的内容，当内核需要切换到另一个进程时，它需要保存当前进程的所有状态，即保存当前进程的进程上下文，以便再次执行该进程时，能够恢复切换时的状态，继续执行。

## 6、从一个文件中读出并将数据传到另一台服务器上的流程
### File.read(file , buf , len)
- 应用程序中调用read方法，这里会涉及到一次上下文切换（用户态-->内核态），底层采用DMA（direct memory access）读取磁盘的文件，并把内容存储到内核地址空间的读取缓存区。
- 由于应用程序无法访问内核地址空间的数据，如果应用程序要操作这些数据，得把这些内容从内核的读取缓冲区拷贝到用户缓冲区。read调用的返回引发一次上下文切换（内核态-->用户态），现在数据已经被拷贝到了用户的地址空间缓冲区，如果有需要，可以修改这些内容。

### Socket.send(socket , buf , len)
- 我们最终的目的是把这个文件内容通过socket传到另一个服务器，调用socket的send方法，又涉及到一次上下文切换（用户态-->内核态），同时，文件内容被进行第三次拷贝，这次的缓冲区与目标套接字相关联，与读取缓冲区无关。
- send调用返回，引发第四次的上下文切换，同时进行第四次拷贝，DMA把数据从目标套接字相关的缓存区传到协议引擎进行发送。  

整个过程中，过程1和4是由DMA负责，并不会消耗CPU，只有过程2和3的拷贝需要CPU参与。如果在应用程序中，不需要操作内容，过程2和3显然是多余的，如果可以直接把内核态读取缓存区数据直接拷贝到套接字相关的缓存区，则上下文切换的次数从四次减少到了两次，拷贝次数从四次减少到了三次（其中DMA copy两次，CPU copy一次）。  
在Linux内核2.4及后期版本中，针对套接字缓冲区描述符做了相应调整，DMA自带了收集功能。

## 7、Page Cache
Page cache是通过将磁盘中的数据缓存到内存中，从而减少磁盘I/O操作，从而提高性能。此外，还要确保在page cache中的数据更改时能够被同步到磁盘上，后者被称为page回写（page writeback）。对磁盘的数据进行缓存从而提高性能主要是基于两个因素：第一，磁盘访问的速度比内存慢好几个数量级（毫秒和纳秒的差距）。第二是被访问过的数据，有很大概率会被再次访问。  
Page cache由内存中的物理page组成，其内容对应磁盘上的block。page cache的大小是动态变化的，可以扩大，也可以在内存不足时缩小。cache缓存的存储设备被称为后备存储（backing store），注意我们在block I/O一文中提到的：一个page通常包含多个block，这些block不一定是连续的。  

- 读Cache：当内核发起一个读请求时（例如进程发起read()请求），首先会检查请求的数据是否缓存到了page cache中，如果有，那么直接从内存中读取，不需要访问磁盘，这被称为cache命中（cache hit）。如果cache中没有请求的数据，即cache未命中（cache miss），就必须从磁盘中读取数据。然后内核将读取的数据缓存到cache中，这样后续的读请求就可以命中cache了。page可以只缓存一个文件部分的内容，不需要把整个文件都缓存进来。
- 写Cache：当内核发起一个写请求时（例如进程发起write()请求），同样是直接往cache中写入，后备存储中的内容不会直接更新。内核会将被写入的page标记为dirty，并将其加入dirty list中。内核会周期性地将dirty list中的page写回到磁盘上，从而使磁盘上的数据和内存中缓存的数据一致。
- Cache回收：Page cache的另一个重要工作是释放page，从而释放内存空间。cache回收的任务是选择合适的page释放，并且如果page是dirty的，需要将page写回到磁盘中再释放。下面先介绍LRU算法，然后介绍基于LRU改进的Two-List策略，后者是Linux使用的策略。
  - LRU算法：LRU（least rencently used)最近最少使用算法是选择最近一次访问时间最靠前的page，即干掉最近没被光顾过的page。原始LRU算法存在的问题是，有些文件只会被访问一次，但是按照LRU的算法，即使这些文件以后再也不会被访问了，但是如果它们是刚刚被访问的，就不会被选中。
  - Two-List策略：Two-List策略维护了两个list，active list 和 inactive list。在active list上的page被认为是hot的，不能释放。只有inactive list上的page可以被释放的。首次缓存的数据的page会被加入到inactive list中，已经在inactive list中的page如果再次被访问，就会移入active list中。两个链表都使用了伪LRU算法维护，新的page从尾部加入，移除时从头部移除，就像队列一样。如果active list中page的数量远大于inactive list，那么active list头部的页面会被移入inactive list中，从而位置两个表的平衡。  

[原文链接](https://blog.csdn.net/damontive/article/details/80552566)


